package alix.lucene;

import java.io.IOException;
import java.io.StringReader;

import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;

public class XmlAnalyzer extends Analyzer
{

  @Override
  protected TokenStreamComponents createComponents(String fieldName)
  {
    return new TokenStreamComponents(new XmlTokenizer());
  }

  public static void main(String[] args) throws IOException
  {
    // text to tokenize
    final String text = "<p>" + "Câ€™est un paragraphe. Avec de <i>l'italique</i>." + "</p>";

    XmlAnalyzer analyzer = new XmlAnalyzer();
    TokenStream stream = analyzer.tokenStream("field", new StringReader(text));

    // get the CharTermAttribute from the TokenStream
    CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);

    try {
      stream.reset();
      // print all tokens until stream is exhausted
      while (stream.incrementToken()) {
        System.out.println(termAtt.toString());
      }
      stream.end();
    }
    finally {
      stream.close();
      analyzer.close();
    }
  }

}
